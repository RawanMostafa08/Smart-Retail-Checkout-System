{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93463bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive features saved in output/positives_features\n",
      "Negative features saved in output/negatives_features\n"
     ]
    }
   ],
   "source": [
    "### Feature Extractor ###\n",
    "\n",
    "# Import the functions to calculate feature descriptors\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "import joblib\n",
    "import cv2\n",
    "# To read file names\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def convert_to_gray(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    orientations = 9\n",
    "    pixels_per_cell = (8, 8)\n",
    "    cells_per_block = (2, 2)\n",
    "    pos_im_path = \"dataset/train/positives\"\n",
    "    neg_im_path = \"dataset/train/negatives\"\n",
    "    pos_feat_ph = (\"output/positives_features\")\n",
    "    neg_feat_ph = (\"output/negatives_features\")\n",
    "        \n",
    "    #\"Calculating the descriptors for the positive samples and saving them\"\n",
    "    for im_path in glob.glob(os.path.join(pos_im_path, \"*\")):\n",
    "        im = imread(im_path)\n",
    "        im = convert_to_gray(im)\n",
    "        fd = hog(im, orientations, pixels_per_cell, cells_per_block)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(pos_feat_ph, fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print (\"Positive features saved in {}\".format(pos_feat_ph))\n",
    "\n",
    "    #\"Calculating the descriptors for the negative samples and saving them\"\n",
    "    for im_path in glob.glob(os.path.join(neg_im_path, \"*\")):\n",
    "        im = imread(im_path)\n",
    "        im = convert_to_gray(im)\n",
    "        fd = hog(im,  orientations, pixels_per_cell, cells_per_block)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(neg_feat_ph, fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"Negative features saved in {}\".format(neg_feat_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "14380884",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 93636\n",
      "Coefficients shape: (1, 93636)\n",
      "Intercept shape: (1,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'n_support_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficients shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf\u001b[38;5;241m.\u001b[39mintercept_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of support vectors for each class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf\u001b[38;5;241m.\u001b[39mn_support_)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'n_support_'"
     ]
    }
   ],
   "source": [
    "### Training the classifier (SVM) ###\n",
    "\n",
    "# Import the functions to calculate feature descriptors\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "import cv2\n",
    "# To read file names\n",
    "import glob\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model_path = \"output/models\"\n",
    "    pos_feat_path = \"output/positives_features\"\n",
    "    neg_feat_path = \"output/negatives_features\"\n",
    "\n",
    "    fds = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load the positive features\n",
    "    for feat_path in glob.glob(os.path.join(pos_feat_path,\"*.feat\")):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd)\n",
    "        labels.append(1)\n",
    "\n",
    "    # Load the negative features\n",
    "    for feat_path in glob.glob(os.path.join(neg_feat_path,\"*.feat\")):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd)\n",
    "        labels.append(0)\n",
    "\n",
    "    #\"Training a Linear SVM Classifier\"\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(fds, labels)\n",
    "    \n",
    "    model_path = os.path.join(\"output/models\", 'model.pkl')\n",
    "    joblib.dump(clf, model_path)    \n",
    "        # Print information about the model\n",
    "    print(\"Number of features:\", clf.coef_.shape[1])\n",
    "    print(\"Coefficients shape:\", clf.coef_.shape)\n",
    "    print(\"Intercept shape:\", clf.intercept_.shape)\n",
    "\n",
    "    \n",
    "    print (\"Classifier saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e32fac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n",
      "[[0.24313725 0.24705882 0.25098039 ... 0.72941176 0.76078431 0.75294118]\n",
      " [0.23137255 0.23529412 0.24313725 ... 0.74117647 0.76470588 0.75294118]\n",
      " [0.21960784 0.22352941 0.22745098 ... 0.75686275 0.77254902 0.75686275]\n",
      " ...\n",
      " [0.39215686 0.35686275 0.3254902  ... 0.44313725 0.44313725 0.44705882]\n",
      " [0.35294118 0.32156863 0.29411765 ... 0.39607843 0.39215686 0.39607843]\n",
      " [0.3254902  0.30196078 0.27843137 ... 0.35686275 0.35686275 0.36078431]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1584 features, but LinearSVC is expecting 93636 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m fd \u001b[38;5;241m=\u001b[39m hog(im_window, orientations, pixels_per_cell, cells_per_block)\n\u001b[0;32m     76\u001b[0m fd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(fd)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to 2D array with one row\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(fd)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetection:: Location -> (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x, y))\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1584 features, but LinearSVC is expecting 93636 features as input."
     ]
    }
   ],
   "source": [
    "### Testing the classifier (SVM) ###\n",
    "\n",
    "# Import the required modules\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from skimage.io import imread\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    '''\n",
    "    This function returns a patch of the input image `image` of size equal\n",
    "    to `window_size`. The first image returned top-left co-ordinates (0, 0) \n",
    "    and are increment in both x and y directions by the `step_size` supplied.\n",
    "    So, the input parameters are -\n",
    "    * `image` - Input Image\n",
    "    * `window_size` - Size of Sliding Window\n",
    "    * `step_size` - Incremented Size of Window\n",
    "\n",
    "    The function returns a tuple -\n",
    "    (x, y, im_window)\n",
    "    where\n",
    "    * x is the top-left x co-ordinate\n",
    "    * y is the top-left y co-ordinate\n",
    "    * im_window is the sliding window image\n",
    "    '''\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Read the image\n",
    "    img = imread(\"dataset/test/Golden-Delicious_021_jpg.rf.87337bfc25366d0027bbd3ddfa4bf26a.jpg\")\n",
    "\n",
    "    im = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    fd = hog(im, orientations, pixels_per_cell, cells_per_block)\n",
    "    fd = np.array(fd).reshape(1, -1)  # Reshape to 2D array with one row\n",
    "    pred = clf.predict(fd)\n",
    "    if pred == 1:\n",
    "        print (\"found\")\n",
    "    else:\n",
    "        print(\"not found\")\n",
    "    \n",
    "    min_wdw_sz = (100, 40)\n",
    "    step_size = (10, 10)\n",
    "    downscale = 1.25\n",
    "    visualize_det = \"store_true\"\n",
    "    orientations = 9\n",
    "    pixels_per_cell = (8, 8)\n",
    "    cells_per_block = (2, 2)\n",
    "\n",
    "    # Load the classifier\n",
    "    clf = joblib.load(\"model.pkl\")\n",
    "\n",
    "    # List to store the detections\n",
    "    detections = []\n",
    "    # The current scale of the image\n",
    "    scale = 0\n",
    "    # Downscale the image and iterate\n",
    "    for im_scaled in pyramid_gaussian(im, downscale=downscale):\n",
    "        # This list contains detections at the current scale\n",
    "        cd = []\n",
    "        # If the width or height of the scaled image is less than\n",
    "        # the width or height of the window, then end the iterations.\n",
    "        if im_scaled.shape[0] < min_wdw_sz[1] or im_scaled.shape[1] < min_wdw_sz[0]:\n",
    "            break\n",
    "        for (x, y, im_window) in sliding_window(im_scaled, min_wdw_sz, step_size):\n",
    "            if im_window.shape[0] != min_wdw_sz[1] or im_window.shape[1] != min_wdw_sz[0]:\n",
    "                continue\n",
    "            # Calculate the HOG features\n",
    "            print(im_window)\n",
    "            fd = hog(im_window, orientations, pixels_per_cell, cells_per_block)\n",
    "            fd = np.array(fd).reshape(1, -1)  # Reshape to 2D array with one row\n",
    "            pred = clf.predict(fd)\n",
    "            if pred == 1:\n",
    "                print (\"Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                print (\"Scale ->  {} | Confidence Score {} \\n\".format(scale,clf.decision_function(fd)))\n",
    "                detections.append((x, y, clf.decision_function(fd),\n",
    "                    int(min_wdw_sz[0]*(downscale**scale)),\n",
    "                    int(min_wdw_sz[1]*(downscale**scale))))\n",
    "                cd.append(detections[-1])\n",
    "        # Mo#ve the the next scale\n",
    "        scale+=1\n",
    "    # Display the results before performing NMS\n",
    "    clone = im.copy()\n",
    "    for (x_tl, y_tl, _, w, h) in detections:\n",
    "        # Draw the detections\n",
    "        cv2.rectangle(im, (x_tl, y_tl), (x_tl+w, y_tl+h), (0, 0, 0), thickness=2)\n",
    "    cv2.imshow(\"Raw Detections before NMS\", im)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    ## Perform Non Maxima Suppression\n",
    "    #detections = nms(detections, threshold)\n",
    "\n",
    "    ## Display the results after performing NMS\n",
    "    #for (x_tl, y_tl, _, w, h) in detections:\n",
    "    #    # Draw the detections\n",
    "    #    cv2.rectangle(clone, (x_tl, y_tl), (x_tl+w,y_tl+h), (0, 0, 0), thickness=2)\n",
    "    #cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "    #cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3492e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e84646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
